<!---
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
-->
<h1 id="apache-hadoop-0.22.0-release-notes">Apache Hadoop 0.22.0 Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, features, and major improvements.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7302">HADOOP-7302</a> | <em>Major</em> | <strong>webinterface.private.actions should not be in common</strong></li>
</ul>
<p>Option webinterface.private.actions has been renamed to mapreduce.jobtracker.webinterface.trusted and should be specified in mapred-site.xml instead of core-site.xml</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7229">HADOOP-7229</a> | <em>Major</em> | <strong>Absolute path to kinit in auto-renewal thread</strong></li>
</ul>
<p>When Hadoop's Kerberos integration is enabled, it is now required that either {{kinit}} be on the path for user accounts running the Hadoop client, or that the {{hadoop.kerberos.kinit.command}} configuration option be manually set to the absolute path to {{kinit}}.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7193">HADOOP-7193</a> | <em>Minor</em> | <strong>Help message is wrong for touchz command.</strong></li>
</ul>
<p>Updated the help for the touchz command.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7192">HADOOP-7192</a> | <em>Trivial</em> | <strong>fs -stat docs aren't updated to reflect the format features</strong></li>
</ul>
<p>Updated the web documentation to reflect the formatting abilities of 'fs -stat'.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7156">HADOOP-7156</a> | <em>Critical</em> | <strong>getpwuid_r is not thread-safe on RHEL6</strong></li>
</ul>
<p>Adds a new configuration hadoop.work.around.non.threadsafe.getpwuid which can be used to enable a mutex around this call to workaround thread-unsafe implementations of getpwuid_r. Users should consult http://wiki.apache.org/hadoop/KnownBrokenPwuidImplementations for a list of such systems.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7137">HADOOP-7137</a> | <em>Major</em> | <strong>Remove hod contrib</strong></li>
</ul>
<p>Removed contrib related build targets.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7134">HADOOP-7134</a> | <em>Major</em> | <strong>configure files that are generated as part of the released tarball need to have executable bit set</strong></li>
</ul>
<p>I have just committed this to trunk and branch-0.22. Thanks Roman!</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7117">HADOOP-7117</a> | <em>Major</em> | <strong>Move secondary namenode checkpoint configs from core-default.xml to hdfs-default.xml</strong></li>
</ul>
<p>Removed references to the older fs.checkpoint.* properties that resided in core-site.xml</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7089">HADOOP-7089</a> | <em>Minor</em> | <strong>Fix link resolution logic in hadoop-config.sh</strong></li>
</ul>
<p>Updates hadoop-config.sh to always resolve symlinks when determining HADOOP_HOME. Bash built-ins or POSIX:2001 compliant cmds are now required.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7013">HADOOP-7013</a> | <em>Major</em> | <strong>Add boolean field isCorrupt to BlockLocation</strong></li>
</ul>
<p>This patch has changed the serialization format of BlockLocation.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7005">HADOOP-7005</a> | <em>Major</em> | <strong>Update test-patch.sh to remove callback to Hudson master</strong></li>
</ul>
<p>N/A</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6949">HADOOP-6949</a> | <em>Major</em> | <strong>Reduces RPC packet size for primitive arrays, especially long[], which is used at block reporting</strong></li>
</ul>
<p>Increments the RPC protocol version in org.apache.hadoop.ipc.Server from 4 to 5. Introduces ArrayPrimitiveWritable for a much more efficient wire format to transmit arrays of primitives over RPC. ObjectWritable uses the new writable for array of primitives for RPC and continues to use existing format for on-disk data.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6922">HADOOP-6922</a> | <em>Major</em> | <strong>COMMON part of MAPREDUCE-1664</strong></li>
</ul>
<p>Makes AccessControlList a writable and updates documentation for Job ACLs.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6905">HADOOP-6905</a> | <em>Major</em> | <strong>Better logging messages when a delegation token is invalid</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6835">HADOOP-6835</a> | <em>Major</em> | <strong>Support concatenated gzip files</strong></li>
</ul>
<p>Processing of concatenated gzip files formerly stopped (quietly) at the end of the first substream/&quot;member&quot;; now processing will continue to the end of the concatenated stream, like gzip(1) does. (bzip2 support is unaffected by this patch.)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6787">HADOOP-6787</a> | <em>Major</em> | <strong>Factor out glob pattern code from FileContext and Filesystem</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6730">HADOOP-6730</a> | <em>Major</em> | <strong>Bug in FileContext#copy and provide base class for FileContext tests</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6693">HADOOP-6693</a> | <em>Major</em> | <strong>Add metrics to track kerberos login activity</strong></li>
</ul>
<p>New metrics &quot;login&quot; of type MetricTimeVaryingRate is added under new metrics context name &quot;ugi&quot; and metrics record name &quot;ugi&quot;.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6683">HADOOP-6683</a> | <em>Minor</em> | <strong>the first optimization: ZlibCompressor does not fully utilize the buffer</strong></li>
</ul>
<p>Improve the buffer utilization of ZlibCompressor to avoid invoking a JNI per write request.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6663">HADOOP-6663</a> | <em>Major</em> | <strong>BlockDecompressorStream get EOF exception when decompressing the file compressed from empty file</strong></li>
</ul>
<p>Fix EOF exception in BlockDecompressorStream when decompressing previous compressed empty file</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6599">HADOOP-6599</a> | <em>Major</em> | <strong>Split RPC metrics into summary and detailed metrics</strong></li>
</ul>
<p>Split existing RpcMetrics into RpcMetrics and RpcDetailedMetrics. The new RpcDetailedMetrics has per method usage details and is available under context name &quot;rpc&quot; and record name &quot;detailed-metrics&quot;</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6436">HADOOP-6436</a> | <em>Major</em> | <strong>Remove auto-generated native build files</strong></li>
</ul>
<p>The native build run when from trunk now requires autotools, libtool and openssl dev libraries.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-6344">HADOOP-6344</a> | <em>Major</em> | <strong>rm and rmr fail to correctly move the user's files to the trash prior to deleting when they are over quota.</strong></li>
</ul>
<p>Trash feature notifies user of over-quota condition rather than silently deleting files/directories; deletion can be compelled with &quot;rm -skiptrash&quot;.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-4675">HADOOP-4675</a> | <em>Major</em> | <strong>Current Ganglia metrics implementation is incompatible with Ganglia 3.1</strong></li>
</ul>
<p>Support for reporting metrics to Ganglia 3.1 servers</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1948">HDFS-1948</a> | <em>Major</em> | <strong>Forward port 'hdfs-1520 lightweight namenode operation to trigger lease reccovery'</strong></li>
</ul>
<p>Adds method to NameNode/ClientProtocol that allows for rude revoke of lease on current lease holder</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1825">HDFS-1825</a> | <em>Major</em> | <strong>Remove thriftfs contrib</strong></li>
</ul>
<p>Removed thriftfs contrib component.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1596">HDFS-1596</a> | <em>Major</em> | <strong>Move secondary namenode checkpoint configs from core-default.xml to hdfs-default.xml</strong></li>
</ul>
<p>Removed references to the older fs.checkpoint.* properties that resided in core-site.xml</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1582">HDFS-1582</a> | <em>Major</em> | <strong>Remove auto-generated native build files</strong></li>
</ul>
<p>The native build run when from trunk now requires autotools, libtool and openssl dev libraries.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1560">HDFS-1560</a> | <em>Minor</em> | <strong>dfs.data.dir permissions should default to 700</strong></li>
</ul>
<p>The permissions on datanode data directories (configured by dfs.datanode.data.dir.perm) now default to 0700. Upon startup, the datanode will automatically change the permissions to match the configured value.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1457">HDFS-1457</a> | <em>Major</em> | <strong>Limit transmission rate when transfering image between primary and secondary NNs</strong></li>
</ul>
<p>Add a configuration variable dfs.image.transfer.bandwidthPerSec to allow the user to specify the amount of bandwidth for transferring image and edits. Its default value is 0 indicating no throttling.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1435">HDFS-1435</a> | <em>Major</em> | <strong>Provide an option to store fsimage compressed</strong></li>
</ul>
<p>This provides an option to store fsimage compressed. The layout version is bumped to -25. The user could configure if s/he wants the fsimage to be compressed or not and which codec to use. By default the fsimage is not compressed.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1318">HDFS-1318</a> | <em>Major</em> | <strong>HDFS Namenode and Datanode WebUI information needs to be accessible programmatically for scripts</strong></li>
</ul>
<p>resubmit the patch for HDFS1318 as Hudson was down last week.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1315">HDFS-1315</a> | <em>Major</em> | <strong>Add fsck event to audit log and remove other audit log events corresponding to FSCK listStatus and open calls</strong></li>
</ul>
<p>When running fsck, audit log events are not logged for listStatus and open are not logged. A new event with cmd=fsck is logged with ugi field set to the user requesting fsck and src field set to the fsck path.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1109">HDFS-1109</a> | <em>Major</em> | <strong>HFTP and URL Encoding</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1096">HDFS-1096</a> | <em>Major</em> | <strong>allow dfsadmin/mradmin refresh of superuser proxy group mappings</strong></li>
</ul>
<p>changed protocol name (may be used in hadoop-policy.xml) from security.refresh.usertogroups.mappings.protocol.acl to security.refresh.user.mappings.protocol.acl</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1080">HDFS-1080</a> | <em>Major</em> | <strong>SecondaryNameNode image transfer should use the defined http address rather than local ip address</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1079">HDFS-1079</a> | <em>Major</em> | <strong>HDFS implementation should throw exceptions defined in AbstractFileSystem</strong></li>
</ul>
<p>Specific exceptions are thrown from HDFS implementation and protocol per the interface defined in AbstractFileSystem. The compatibility is not affected as the applications catch IOException and will be able to handle specific exceptions that are subclasses of IOException.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1061">HDFS-1061</a> | <em>Minor</em> | <strong>Memory footprint optimization for INodeFile object.</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1035">HDFS-1035</a> | <em>Major</em> | <strong>Generate Eclipse's .classpath file from Ivy config</strong></li>
</ul>
<p>Added support to auto-generate the Eclipse .classpath file from ivy.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-903">HDFS-903</a> | <em>Critical</em> | <strong>NN should verify images and edit logs on startup</strong></li>
</ul>
<p>Store fsimage MD5 checksum in VERSION file. Validate checksum when loading a fsimage. Layout version bumped.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-712">HDFS-712</a> | <em>Major</em> | <strong>Move libhdfs from mr to hdfs</strong></li>
</ul>
<p>Moved the libhdfs package to the HDFS subproject.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-708">HDFS-708</a> | <em>Major</em> | <strong>A stress-test tool for HDFS.</strong></li>
</ul>
<p>Does not currently provide anything but uniform distribution. Uses some older depreciated class interfaces (for mapper and reducer) This was tested on 0.20 and 0.22 (locally) so it should be fairly backwards compatible.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-330">HDFS-330</a> | <em>Trivial</em> | <strong>Datanode Web UIs should provide robots.txt</strong></li>
</ul>
<p>A robots.txt is now in place which will prevent well behaved crawlers from perusing Hadoop web interfaces.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-202">HDFS-202</a> | <em>Major</em> | <strong>Add a bulk FIleSystem.getFileBlockLocations</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-3151">MAPREDUCE-3151</a> | <em>Major</em> | <strong>Contrib tests failing</strong></li>
</ul>
<p>Confirmed that problem of finding ivy file occurs w/o patch with ant 1.7, and not with patch (with either ant 1.7 or 1.8). Other unit tests are still failing the test steps themselves on my laptop, but that is not due not finding the ivy file.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2516">MAPREDUCE-2516</a> | <em>Minor</em> | <strong>option to control sensitive web actions</strong></li>
</ul>
<p>Configuration option webinterface.private.actions has been renamed to mapreduce.jobtracker.webinterface.trusted</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2410">MAPREDUCE-2410</a> | <em>Minor</em> | <strong>document multiple keys per reducer oddity in hadoop streaming FAQ</strong></li>
</ul>
<p>Add an FAQ entry regarding the differences between Java API and Streaming development of MR programs.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2272">MAPREDUCE-2272</a> | <em>Trivial</em> | <strong>Job ACL file should not be executable</strong></li>
</ul>
<p>Job ACL files now have permissions set to 600 (previously 700).</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2260">MAPREDUCE-2260</a> | <em>Major</em> | <strong>Remove auto-generated native build files</strong></li>
</ul>
<p>The native build run when from trunk now requires autotools, libtool and openssl dev libraries.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2251">MAPREDUCE-2251</a> | <em>Major</em> | <strong>Remove mapreduce.job.userhistorylocation config</strong></li>
</ul>
<p>Remove the now defunct property <code>mapreduce.job.userhistorylocation</code>.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2147">MAPREDUCE-2147</a> | <em>Trivial</em> | <strong>JobInProgress has some redundant lines in its ctor</strong></li>
</ul>
<p>Remove some redundant lines from JobInProgress's constructor which was re-initializing things unnecessarily.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2096">MAPREDUCE-2096</a> | <em>Blocker</em> | <strong>Secure local filesystem IO from symlink vulnerabilities</strong></li>
</ul>
<p>The TaskTracker now uses the libhadoop JNI library to operate securely on local files when security is enabled. Secure clusters must ensure that libhadoop.so is available to the TaskTracker.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2054">MAPREDUCE-2054</a> | <em>Major</em> | <strong>Hierarchical queue implementation broke dynamic queue addition in Dynamic Scheduler</strong></li>
</ul>
<p>Fix Dynamic Priority Scheduler to work with hierarchical queue names</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2032">MAPREDUCE-2032</a> | <em>Major</em> | <strong>TestJobOutputCommitter fails in ant test run</strong></li>
</ul>
<p>Clears a problem that {{TestJobCleanup}} leaves behind files that cause {{TestJobOutputCommitter}} to error out.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1996">MAPREDUCE-1996</a> | <em>Trivial</em> | <strong>API: Reducer.reduce() method detail misstatement</strong></li>
</ul>
<p>Fix a misleading documentation note about the usage of Reporter objects in Reducers.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1905">MAPREDUCE-1905</a> | <em>Blocker</em> | <strong>Context.setStatus() and progress() api are ignored</strong></li>
</ul>
<p>Moved the api public Counter getCounter(Enum&lt;?&gt; counterName), public Counter getCounter(String groupName, String counterName) from org.apache.hadoop.mapreduce.TaskInputOutputContext to org.apache.hadoop.mapreduce.TaskAttemptContext</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1887">MAPREDUCE-1887</a> | <em>Major</em> | <strong>MRAsyncDiskService does not properly absolutize volume root paths</strong></li>
</ul>
<p>MAPREDUCE-1887. MRAsyncDiskService now properly absolutizes volume root paths. (Aaron Kimball via zshao)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1866">MAPREDUCE-1866</a> | <em>Minor</em> | <strong>Remove deprecated class org.apache.hadoop.streaming.UTF8ByteArrayUtils</strong></li>
</ul>
<p>Removed public deprecated class org.apache.hadoop.streaming.UTF8ByteArrayUtils.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1836">MAPREDUCE-1836</a> | <em>Major</em> | <strong>Refresh for proxy superuser config (mr part for HDFS-1096)</strong></li>
</ul>
<p>changing name of the protocol (may be used in hadoop-policy.xml) from security.refresh.usertogroups.mappings.protocol.acl to security.refresh.user.mappings.protocol.acl</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1829">MAPREDUCE-1829</a> | <em>Major</em> | <strong>JobInProgress.findSpeculativeTask should use min() to find the candidate instead of sort()</strong></li>
</ul>
<p>Improved performance of the method JobInProgress.findSpeculativeTask() which is in the critical heartbeat code path.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1813">MAPREDUCE-1813</a> | <em>Major</em> | <strong>NPE in PipeMapred.MRErrorThread</strong></li>
</ul>
<p>Fixed an NPE in streaming that occurs when there is no input to reduce and the streaming reducer sends status updates by writing &quot;reporter:status: xxx&quot; statements to stderr.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1785">MAPREDUCE-1785</a> | <em>Minor</em> | <strong>Add streaming config option for not emitting the key</strong></li>
</ul>
<p>Added a configuration property &quot;stream.map.input.ignoreKey&quot; to specify whether to ignore key or not while writing input for the mapper. This configuration parameter is valid only if stream.map.input.writer.class is org.apache.hadoop.streaming.io.TextInputWriter.class. For all other InputWriter's, key is always written.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1780">MAPREDUCE-1780</a> | <em>Major</em> | <strong>AccessControlList.toString() is used for serialization of ACL in JobStatus.java</strong></li>
</ul>
<p>Fixes serialization of job-acls in JobStatus to use AccessControlList.write() instead of AccessControlList.toString().</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1773">MAPREDUCE-1773</a> | <em>Major</em> | <strong>streaming doesn't support jobclient.output.filter</strong></li>
</ul>
<p>Improved console messaging for streaming jobs by using the generic JobClient API itself instead of the existing streaming-specific code.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1733">MAPREDUCE-1733</a> | <em>Major</em> | <strong>Authentication between pipes processes and java counterparts.</strong></li>
</ul>
<p>This jira introduces backward incompatibility. Existing pipes applications MUST be recompiled with new hadoop pipes library once the changes in this jira are deployed.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1707">MAPREDUCE-1707</a> | <em>Major</em> | <strong>TaskRunner can get NPE in getting ugi from TaskTracker</strong></li>
</ul>
<p>Fixed a bug that causes TaskRunner to get NPE in getting ugi from TaskTracker and subsequently crashes it resulting in a failing task after task-timeout period.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1683">MAPREDUCE-1683</a> | <em>Major</em> | <strong>Remove JNI calls from ClusterStatus cstr</strong></li>
</ul>
<p>Removes JNI calls to get jvm current/max heap usage in ClusterStatus. Any instances of ClusterStatus serialized in a prior version will not be correctly deserialized using the updated class.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1680">MAPREDUCE-1680</a> | <em>Major</em> | <strong>Add a metrics to track the number of heartbeats processed</strong></li>
</ul>
<p>Added a metric to track number of heartbeats processed by the JobTracker.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1664">MAPREDUCE-1664</a> | <em>Major</em> | <strong>Job Acls affect Queue Acls</strong></li>
</ul>
<p>* Removed aclsEnabled flag from queues configuration files. * Removed the configuration property mapreduce.cluster.job-authorization-enabled. * Added mapreduce.cluster.acls.enabled as the single configuration property in mapred-default.xml that enables the authorization checks for all job level and queue level operations. * To enable authorization of users to do job level and queue level operations, mapreduce.cluster.acls.enabled is to be set to true in JobTracker's configuration and in all TaskTrackers' configurations. * To get access to a job, it is enough for a user to be part of one of the access lists i.e. either job-acl or queue-admins-acl(unlike before, when, one has to be part of both the lists). * Queue administrators(configured via acl-administer-jobs) of a queue can do all view-job and modify-job operations on all jobs submitted to that queue. * ClusterOwner(who started the mapreduce cluster) and cluster administrators(configured via mapreduce.cluster.permissions.supergroup) can do all job level operations and queue level operations on all jobs on all queues in that cluster irrespective of job-acls and queue-acls configured. * JobOwner(who submitted job to a queue) can do all view-job and modify-job operations on his/her job irrespective of job-acls and queue-acls. * Since aclsEnabled flag is removed from queues configuration files, &quot;refresh of queues configuration&quot; will not change mapreduce.cluster.acls.enabled on the fly. mapreduce.cluster.acls.enabled can be modified only when restarting the mapreduce cluster.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1592">MAPREDUCE-1592</a> | <em>Major</em> | <strong>Generate Eclipse's .classpath file from Ivy config</strong></li>
</ul>
<p>Added support to auto-generate the Eclipse .classpath file from ivy.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1558">MAPREDUCE-1558</a> | <em>Major</em> | <strong>specify correct server principal for RefreshAuthorizationPolicyProtocol and RefreshUserToGroupMappingsProtocol protocols in MRAdmin (for HADOOP-6612)</strong></li>
</ul>
<p>new config: hadoop.security.service.user.name.key this setting points to the server principal for RefreshUserToGroupMappingsProtocol. The value should be either NN or JT principal depending if it is used in DFAdmin or MRAdmin. The value is set by the application. No need for default value.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1543">MAPREDUCE-1543</a> | <em>Major</em> | <strong>Log messages of JobACLsManager should use security logging of HADOOP-6586</strong></li>
</ul>
<p>Adds the audit logging facility to MapReduce. All authorization/authentication events are logged to audit log. Audit log entries are stored as key=value.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1533">MAPREDUCE-1533</a> | <em>Major</em> | <strong>Reduce or remove usage of String.format() usage in CapacityTaskScheduler.updateQSIObjects and Counters.makeEscapedString()</strong></li>
</ul>
<p>Incremental enhancements to the JobTracker to optimize heartbeat handling.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1517">MAPREDUCE-1517</a> | <em>Major</em> | <strong>streaming should support running on background</strong></li>
</ul>
<p>Adds -background option to run a streaming job in background.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1505">MAPREDUCE-1505</a> | <em>Major</em> | <strong>Cluster class should create the rpc client only when needed</strong></li>
</ul>
<p>Lazily construct a connection to the JobTracker from the job-submission client.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1354">MAPREDUCE-1354</a> | <em>Critical</em> | <strong>Incremental enhancements to the JobTracker for better scalability</strong></li>
</ul>
<p>Incremental enhancements to the JobTracker include a no-lock version of JT.getTaskCompletion events, no lock on the JT while doing i/o during job-submission and several fixes to cut down configuration parsing during heartbeat-handling.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1159">MAPREDUCE-1159</a> | <em>Trivial</em> | <strong>Limit Job name on jobtracker.jsp to be 80 char long</strong></li>
</ul>
<p>Job names on jobtracker.jsp should be 80 characters long at most.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-1118">MAPREDUCE-1118</a> | <em>Major</em> | <strong>Capacity Scheduler scheduling information is hard to read / should be tabular format</strong></li>
</ul>
<p>Add CapacityScheduler servlet to enhance web UI for queue information.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-927">MAPREDUCE-927</a> | <em>Major</em> | <strong>Cleanup of task-logs should happen in TaskTracker instead of the Child</strong></li>
</ul>
<p>Moved Task log cleanup into a separate thread in TaskTracker.<br />
Added configuration &quot;mapreduce.job.userlog.retain.hours&quot; to specify the time(in hours) for which the user-logs are to be retained after the job completion.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-572">MAPREDUCE-572</a> | <em>Minor</em> | <strong>If #link is missing from uri format of -cacheArchive then streaming does not throw error.</strong></li>
</ul>
<p>Improved streaming job failure when #link is missing from uri format of -cacheArchive. Earlier it used to fail when launching individual tasks, now it fails during job submission itself.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-478">MAPREDUCE-478</a> | <em>Minor</em> | <strong>separate jvm param for mapper and reducer</strong></li>
</ul>
<p>Allow map and reduce jvm parameters, environment variables and ulimit to be set separately.</p>
<p>Configuration changes: add mapred.map.child.java.opts add mapred.reduce.child.java.opts add mapred.map.child.env add mapred.reduce.child.ulimit add mapred.map.child.env add mapred.reduce.child.ulimit deprecated mapred.child.java.opts deprecated mapred.child.env deprecated mapred.child.ulimit</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-220">MAPREDUCE-220</a> | <em>Major</em> | <strong>Collecting cpu and memory usage for MapReduce tasks</strong></li>
</ul>
<p>Collect cpu and memory statistics per task.</p>
