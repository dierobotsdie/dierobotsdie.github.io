<!---
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
-->
<h1 id="apache-hadoop-0.20.205.0-release-notes">Apache Hadoop 0.20.205.0 Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, features, and major improvements.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7724">HADOOP-7724</a> | <em>Major</em> | <strong>hadoop-setup-conf.sh should put proxy user info into the core-site.xml</strong></li>
</ul>
<p>Fixed hadoop-setup-conf.sh to put proxy user in core-site.xml. (Arpit Gupta via Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7720">HADOOP-7720</a> | <em>Major</em> | <strong>improve the hadoop-setup-conf.sh to read in the hbase user and setup the configs</strong></li>
</ul>
<p>Added parameter for HBase user to setup config script. (Arpit Gupta via Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7715">HADOOP-7715</a> | <em>Major</em> | <strong>see log4j Error when running mr jobs and certain dfs calls</strong></li>
</ul>
<p>Removed unnecessary security logger configuration. (Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7711">HADOOP-7711</a> | <em>Major</em> | <strong>hadoop-env.sh generated from templates has duplicate info</strong></li>
</ul>
<p>Fixed recursive sourcing of HADOOP_OPTS environment variables (Arpit Gupta via Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7708">HADOOP-7708</a> | <em>Critical</em> | <strong>config generator does not update the properties file if on exists already</strong></li>
</ul>
<p>Fixed hadoop-setup-conf.sh to handle config file consistently. (Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7707">HADOOP-7707</a> | <em>Major</em> | <strong>improve config generator to allow users to specify proxy user, turn append on or off, turn webhdfs on or off</strong></li>
</ul>
<p>Added toggle for dfs.support.append, webhdfs and hadoop proxy user to setup config script. (Arpit Gupta via Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7691">HADOOP-7691</a> | <em>Major</em> | <strong>hadoop deb pkg should take a diff group id</strong></li>
</ul>
<p>Fixed conflict uid for install packages. (Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7684">HADOOP-7684</a> | <em>Major</em> | <strong>jobhistory server and secondarynamenode should have init.d script</strong></li>
</ul>
<p>Added init.d script for jobhistory server and secondary namenode. (Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7681">HADOOP-7681</a> | <em>Minor</em> | <strong>log4j.properties is missing properties for security audit and hdfs audit should be changed to info</strong></li>
</ul>
<p>HADOOP-7681. Fixed security and hdfs audit log4j properties (Arpit Gupta via Eric Yang)</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7655">HADOOP-7655</a> | <em>Major</em> | <strong>provide a small validation script that smoke tests the installed cluster</strong></li>
</ul>
<p>Committed to trunk and v23, since code reviewed by Eric.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7603">HADOOP-7603</a> | <em>Major</em> | <strong>Set default hdfs, mapred uid, and hadoop group gid for RPM packages</strong></li>
</ul>
<p>Set hdfs uid, mapred uid, and hadoop gid to fixed numbers (201, 202, and 123, respectively).</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-7119">HADOOP-7119</a> | <em>Major</em> | <strong>add Kerberos HTTP SPNEGO authentication support to Hadoop JT/NN/DN/TT web-consoles</strong></li>
</ul>
<p>Adding support for Kerberos HTTP SPNEGO authentication to the Hadoop web-consoles</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-2358">HDFS-2358</a> | <em>Major</em> | <strong>NPE when the default filesystem's uri has no authority</strong></li>
</ul>
<p>Give meaningful error message instead of NPE.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-2338">HDFS-2338</a> | <em>Major</em> | <strong>Configuration option to enable/disable webhdfs.</strong></li>
</ul>
<p>Added a conf property dfs.webhdfs.enabled for enabling/disabling webhdfs.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-2318">HDFS-2318</a> | <em>Major</em> | <strong>Provide authentication to webhdfs using SPNEGO</strong></li>
</ul>
<p>Added two new conf properties dfs.web.authentication.kerberos.principal and dfs.web.authentication.kerberos.keytab for the SPNEGO servlet filter.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-2202">HDFS-2202</a> | <em>Major</em> | <strong>Changes to balancer bandwidth should not require datanode restart.</strong></li>
</ul>
<p>New dfsadmin command added: [-setBalancerBandwidth &lt;bandwidth&gt;] where bandwidth is max network bandwidth in bytes per second that the balancer is allowed to use on each datanode during balacing.</p>
<p>This is an incompatible change in 0.23. The versions of ClientProtocol and DatanodeProtocol are changed.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1554">HDFS-1554</a> | <em>Major</em> | <strong>Append 0.20: New semantics for recoverLease</strong></li>
</ul>
<p>Change recoverLease API to return if the file is closed or not. It also change the semantics of recoverLease to start lease recovery immediately.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-630">HDFS-630</a> | <em>Major</em> | <strong>In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this incompatible change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-3112">MAPREDUCE-3112</a> | <em>Major</em> | <strong>Calling hadoop cli inside mapreduce job leads to errors</strong></li>
</ul>
<p>Removed inheritance of certain server environment variables (HADOOP_OPTS and HADOOP_ROOT_LOGGER) in task attempt process.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-3081">MAPREDUCE-3081</a> | <em>Major</em> | <strong>Change the name format for hadoop core and vaidya jar to be hadoop-{core/vaidya}-{version}.jar in vaidya.sh</strong></li>
</ul>
<p>contrib/vaidya/bin/vaidya.sh script fixed to use appropriate jars and classpath</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2777">MAPREDUCE-2777</a> | <em>Major</em> | <strong>Backport MAPREDUCE-220 to Hadoop 20 security branch</strong></li>
</ul>
<p>Adds cumulative cpu usage and total heap usage to task counters. This is a backport of MAPREDUCE-220 and MAPREDUCE-2469.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2764">MAPREDUCE-2764</a> | <em>Major</em> | <strong>Fix renewal of dfs delegation tokens</strong></li>
</ul>
<p>Generalizes token renewal and canceling to a common interface and provides a plugin interface for adding renewers for new kinds of tokens. Hftp changed to store the tokens as HFTP and renew them over http.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2494">MAPREDUCE-2494</a> | <em>Major</em> | <strong>Make the distributed cache delete entires using LRU priority</strong></li>
</ul>
<p>Added config option mapreduce.tasktracker.cache.local.keep.pct to the TaskTracker. It is the target percentage of the local distributed cache that should be kept in between garbage collection runs. In practice it will delete unused distributed cache entries in LRU order until the size of the cache is less than mapreduce.tasktracker.cache.local.keep.pct of the maximum cache size. This is a floating point value between 0.0 and 1.0. The default is 0.95.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-2187">MAPREDUCE-2187</a> | <em>Major</em> | <strong>map tasks timeout during sorting</strong></li>
</ul>
<p>I just committed this. Thanks Anupam!</p>
