<!---
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
-->
<h1 id="apache-hadoop-0.17.2-release-notes">Apache Hadoop 0.17.2 Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, features, and major improvements.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-3859">HADOOP-3859</a> | <em>Blocker</em> | <strong>1000 concurrent read on a single file failing the task/client</strong></li>
</ul>
<p>Allows the user to change the maximum number of xceivers in the datanode.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-3760">HADOOP-3760</a> | <em>Blocker</em> | <strong>DFS operations fail because of Stream closed error</strong></li>
</ul>
<p>Fix a bug with HDFS file close() mistakenly introduced by HADOOP-3681.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-3707">HADOOP-3707</a> | <em>Blocker</em> | <strong>Frequent DiskOutOfSpaceException on almost-full datanodes</strong></li>
</ul>
<p>NameNode keeps a count of number of blocks scheduled to be written to a datanode and uses it to avoid allocating more blocks than a datanode can hold.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-3678">HADOOP-3678</a> | <em>Blocker</em> | <strong>Avoid spurious &quot;DataXceiver: java.io.IOException: Connection reset by peer&quot; errors in DataNode log</strong></li>
</ul>
<p>Avoid spurious exceptions logged at DataNode when clients read from DFS.</p>
