<!---
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
-->
<h1 id="apache-hadoop-2.9.0-release-notes">Apache Hadoop 2.9.0 Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, important issues, features, and major improvements.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-9525">HDFS-9525</a> | <em>Blocker</em> | <strong>hadoop utilities need to support provided delegation tokens</strong></li>
</ul>
<p>If hadoop.token.files property is defined and configured to one or more comma-delimited delegation token files, Hadoop will use those token files to connect to the services as named in the token.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-6622">MAPREDUCE-6622</a> | <em>Critical</em> | <strong>Add capability to set JHS job cache to a task-based limit</strong></li>
</ul>
<p>Two recommendations for the mapreduce.jobhistory.loadedtasks.cache.size property: 1) For every 100k of cache size, set the heap size of the Job History Server to 1.2GB. For example, mapreduce.jobhistory.loadedtasks.cache.size=500000, heap size=6GB. 2) Make sure that the cache size is larger than the number of tasks required for the largest job run on the cluster. It might be a good idea to set the value slightly higher (say, 20%) in order to allow for job size growth.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/YARN-4762">YARN-4762</a> | <em>Blocker</em> | <strong>NMs failing on DelegatingLinuxContainerRuntime init with LCE on</strong></li>
</ul>
<p>Fixed CgroupHandler's creation and usage to avoid NodeManagers crashing when LinuxContainerExecutor is enabled.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-1477">HDFS-1477</a> | <em>Major</em> | <strong>Support reconfiguring dfs.heartbeat.interval and dfs.namenode.heartbeat.recheck-interval without NN restart</strong></li>
</ul>
<p>Steps to reconfigure: 1. change value of the parameter in corresponding xml configuration file 2. to reconfigure, run hdfs dfsadmin -reconfig namenode &lt;nn_addr&gt;:&lt;ipc_port&gt; start 3. to check status of the most recent reconfigure operation, run hdfs dfsadmin -reconfig namenode &lt;nn_addr&gt;:&lt;ipc_port&gt; status 4. to query a list reconfigurable properties on NN, run hdfs dfsadmin -reconfig namenode &lt;nn_addr&gt;:&lt;ipc_port&gt; properties</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/YARN-4732">YARN-4732</a> | <em>Trivial</em> | <strong>*ProcessTree classes have too many whitespace issues</strong></li>
</ul>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-9349">HDFS-9349</a> | <em>Major</em> | <strong>Support reconfiguring fs.protected.directories without NN restart</strong></li>
</ul>
<p>Steps to reconfigure: 1. change value of the parameter in corresponding xml configuration file 2. to reconfigure, run hdfs dfsadmin -reconfig namenode &lt;nn_addr&gt;:&lt;ipc_port&gt; start 3. to check status of the most recent reconfigure operation, run hdfs dfsadmin -reconfig namenode &lt;nn_addr&gt;:&lt;ipc_port&gt; status 4. to query a list reconfigurable properties on NN, run hdfs dfsadmin -reconfig namenode &lt;nn_addr&gt;:&lt;ipc_port&gt; properties</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/MAPREDUCE-6670">MAPREDUCE-6670</a> | <em>Minor</em> | <strong>TestJobListCache#testEviction sometimes fails on Windows with timeout</strong></li>
</ul>
<p>Backport the fix to 2.7 and 2.8</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/YARN-4784">YARN-4784</a> | <em>Major</em> | <strong>Fairscheduler: defaultQueueSchedulingPolicy should not accept FIFO</strong></li>
</ul>
<p>Clusters cannot use FIFO policy as the defaultQueueSchedulingPolicy. Clusters with a single level of queues will have to explicitly set the policy to FIFO if that is desired.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-3702">HDFS-3702</a> | <em>Minor</em> | <strong>Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client</strong></li>
</ul>
<p>This patch will attempt to allocate all replicas to remote DataNodes, by adding local DataNode to the excluded DataNodes. If no sufficient replicas can be obtained, it will fall back to default block placement policy, which writes one replica to local DataNode.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-10694">HADOOP-10694</a> | <em>Major</em> | <strong>Remove synchronized input streams from Writable deserialization</strong></li>
</ul>
<p>Remove invisible synchronization primitives from DataInputBuffer</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-9016">HDFS-9016</a> | <em>Major</em> | <strong>Display upgrade domain information in fsck</strong></li>
</ul>
<p>New fsck option &quot;-upgradedomains&quot; has been added to display upgrade domains of any block.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-10328">HDFS-10328</a> | <em>Minor</em> | <strong>Add per-cache-pool default replication num configuration</strong></li>
</ul>
<p>Add per-cache-pool default replication num configuration</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-13354">HADOOP-13354</a> | <em>Major</em> | <strong>Update WASB driver to use the latest version (4.2.0) of SDK for Microsoft Azure Storage Clients</strong></li>
</ul>
<p>The WASB FileSystem now uses version 4.2.0 of the Azure Storage SDK.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-13403">HADOOP-13403</a> | <em>Major</em> | <strong>AzureNativeFileSystem rename/delete performance improvements</strong></li>
</ul>
<p>WASB has added an optional capability to execute certain FileSystem operations in parallel on multiple threads for improved performance. Please refer to the Azure Blob Storage documentation page for more information on how to enable and control the feature.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-12747">HADOOP-12747</a> | <em>Major</em> | <strong>support wildcard in libjars argument</strong></li>
</ul>
<p>It is now possible to specify multiple jar files for the libjars argument using a wildcard. For example, you can specify &quot;-libjars 'libs/*'&quot; as a shorthand for all jars in the libs directory.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/YARN-5137">YARN-5137</a> | <em>Major</em> | <strong>Make DiskChecker pluggable in NodeManager</strong></li>
</ul>
<p>Added new plugin property yarn.nodemanager.disk-validator to allow the NodeManager to use an alternate class for checking whether a disk is good or not.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HADOOP-13208">HADOOP-13208</a> | <em>Minor</em> | <strong>S3A listFiles(recursive=true) to do a bulk listObjects instead of walking the pseudo-tree of directories</strong></li>
</ul>
<p>S3A has optimized the listFiles method by doing a bulk listing of all entries under a path in a single S3 operation instead of recursively walking the directory tree. The listLocatedStatus method has been optimized by fetching results from S3 lazily as the caller traverses the returned iterator instead of doing an eager fetch of all possible results.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HDFS-8312">HDFS-8312</a> | <em>Critical</em> | <strong>Trash does not descent into child directories to check for permissions</strong></li>
</ul>
<p>HDFS-8312. Added permission check for moving file to Trash. (Weiwei Yang via Eric Yang)</p>
